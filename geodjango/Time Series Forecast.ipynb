{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DataMiningLab\\geodjango\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from io import StringIO\n",
    "import contextlib\n",
    "\n",
    "pwd = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(pwd)\n",
    "\n",
    "sys.path.append(pwd + \"../\")\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"geodjango.settings\")\n",
    "import django\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyflux as pf\n",
    "import types\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import MO\n",
    "django.setup()\n",
    "from django.db.models import Count, Sum, Avg, Q, Func, F\n",
    "from taxi.models import Trip,Edge,District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = 'edges_fig/'\n",
    "def edges():\n",
    "    return Edge.objects.all().filter(tripset = 29)\n",
    "\n",
    "class Day(Func):\n",
    "    function = 'date_trunc'\n",
    "    template = '%(function)s(\\'day\\',%(expressions)s)'\n",
    "    \n",
    "def colname(tail,head):\n",
    "    return 'd'+str(tail)+'_d'+str(head)\n",
    "\n",
    "def plot_fit(self, data_name = None, model='ARIMA', **kwargs):\n",
    "    \"\"\" \n",
    "    Plots the fit of the model against the data\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "    import matplotlib.dates as mdates\n",
    "    from matplotlib.dates import MO\n",
    "    months = mdates.MonthLocator()  # every month\\\n",
    "    weeks = mdates.WeekdayLocator(byweekday=MO)\n",
    "    monthsFmt = mdates.DateFormatter('%m')\n",
    "\n",
    "    figsize = kwargs.get('figsize',(10,7))\n",
    "    plt.figure(figsize=figsize)\n",
    "    date_index = self.index[max(self.ar, self.ma):self.data_length].to_pydatetime()\n",
    "    mu, Y = self._model(self.latent_variables.get_z_values())\n",
    "\n",
    "    # Catch specific family properties (imply different link functions/moments)\n",
    "    if self.model_name2 == \"Exponential\":\n",
    "        values_to_plot = 1.0/self.link(mu)\n",
    "    elif self.model_name2 == \"Skewt\":\n",
    "        t_params = self.transform_z()\n",
    "        model_scale, model_shape, model_skewness = self._get_scale_and_shape(t_params)\n",
    "        m1 = (np.sqrt(model_shape)*sp.gamma((model_shape-1.0)/2.0))/(np.sqrt(np.pi)*sp.gamma(model_shape/2.0))\n",
    "        additional_loc = (model_skewness - (1.0/model_skewness))*model_scale*m1\n",
    "        values_to_plot = mu + additional_loc\n",
    "    else:\n",
    "        values_to_plot = self.link(mu)\n",
    "\n",
    "    plt.plot_date(date_index, Y,'-', label='Data')\n",
    "    plt.plot_date(date_index, values_to_plot,'-', label=model+' model', c='black')\n",
    "    if data_name is not None:\n",
    "        plt.title(data_name)\n",
    "    else:\n",
    "        plt.title(self.data_name)#(label())#\n",
    "    plt.legend(loc=2)\n",
    "    \n",
    "@contextlib.contextmanager\n",
    "def stdoutIO(stdout=None):\n",
    "    old = sys.stdout\n",
    "    if stdout is None:\n",
    "        stdout = StringIO()\n",
    "    sys.stdout = stdout\n",
    "    yield stdout\n",
    "    sys.stdout = old\n",
    "    \n",
    "class EdgeTimeSeries():\n",
    "    def __init__(self,tail,head,df_all_ets = None):\n",
    "        self.tail = tail\n",
    "        self.head = head\n",
    "        self.neighbour_tail = edges().filter(tail=tail).exclude(head=tail).exclude(head=head).order_by('-weight')[:3].values_list('head',flat=True)\n",
    "        self.neighbour_head = edges().filter(head=head).exclude(tail=head).exclude(tail=tail).order_by('-weight')[:3].values_list('tail',flat=True)\n",
    "        if df_all_ets is not None:\n",
    "            self.data = df_all_ets[self.cols()]\n",
    "    def set_data(self,df_all_ets):\n",
    "        self.data = df_all_ets[self.cols()]\n",
    "    def cols(self):\n",
    "        return list(set([colname(self.tail,h) for h in self.neighbour_tail] +  \\\n",
    "                        [colname(t,self.head) for t in self.neighbour_head] +  \\\n",
    "                        [self.target(),self.target(),self.target_inv()]))\n",
    "    def label(self):\n",
    "        return District.objects.get(pk=self.tail).name+'->'+District.objects.get(pk=self.head).name\n",
    "    def target(self):\n",
    "        return colname(self.tail,self.head)\n",
    "    def target_inv(self):\n",
    "        return colname(self.head,self.tail)\n",
    "    def formula(self):\n",
    "        return self.target()+'~1+'+'+'.join([str(x) for x in self.data.columns.values[self.data.columns.values!=self.target()]])\n",
    "    def plot_serie(self):\n",
    "        fig, ax = plt.subplots(figsize=(25, 10))\n",
    "        months = mdates.MonthLocator()  # every month\\\n",
    "        weeks = mdates.WeekdayLocator(byweekday=MO)\n",
    "        monthsFmt = mdates.DateFormatter('%m')\n",
    "        ax.xaxis.set_major_formatter(monthsFmt)\n",
    "        ax.xaxis.set_minor_locator(weeks)\n",
    "        ax.set_xlabel(\"Month\")\n",
    "        ax.set_ylabel(\"Number of trips\")\n",
    "        ax.plot_date(self.data.index.to_pydatetime(), self.data.values, '-')\n",
    "        ax.plot_date(self.data.index.to_pydatetime(), self.data[[self.target()]].values, '-',label=self.label())\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.autoscale(enable=True, axis='y', tight=True)\n",
    "        ax.set_ylim(bottom=0)\n",
    "        plt.savefig(PATH+self.target()+\".png\",bbox_inches='tight')\n",
    "    def plot_predict(self,mode = 'ARIMAX', h=10, past_values=10, intervals=True, **kwargs):\n",
    "        figsize=(20,5)\n",
    "        time = self.data.index.to_pydatetime()\n",
    "        val =  self.data[self.target()].values\n",
    "        time_steps = [-10,-20,-30]\n",
    "        for idx, ts in enumerate(time_steps):\n",
    "            if mode is 'ARIMA':\n",
    "                m = pf.ARIMA(data=self.data[:ts],target = self.target(), ar=7, ma=7, family=pf.Normal())\n",
    "                m.fit(\"MLE\")\n",
    "                m.plot_predict(h, past_values, intervals,figsize=figsize, **kwargs)\n",
    "            else:\n",
    "                m = pf.ARIMAX(data=self.data[:ts], ar=7, ma=7,formula=self.formula(),family=pf.Normal())\n",
    "                m.fit(\"MLE\")\n",
    "                m.plot_predict(h, past_values, intervals,figsize=figsize,oos_data=self.data[ts:], **kwargs)\n",
    "            plt.plot_date(time, val, '-',label=self.label())\n",
    "            plt.xlim(pd.Timestamp('2016-05-31'), pd.Timestamp('2016-06-30'))\n",
    "            plt.legend()\n",
    "            plt.savefig(PATH+self.target()+'_'+mode+'_'+str(idx)+\".png\",bbox_inches='tight')\n",
    "    def arima(self):\n",
    "        self.arima = pf.ARIMA(data=self.data,target = self.target(), ar=7, ma=7, family=pf.Normal())\n",
    "        self.arima.plot_fit = types.MethodType(plot_fit, self.arima)\n",
    "        self.arima_res = self.arima.fit(\"MLE\")\n",
    "        with stdoutIO() as s:\n",
    "            self.arima_res.summary()\n",
    "        with open(PATH+self.target()+\"_ARIMA.txt\", \"w\") as text_file:\n",
    "            text_file.write(s.getvalue())\n",
    "        self.arima.plot_fit(figsize=(25,5),model='ARIMA')\n",
    "        plt.savefig(PATH+self.target()+\"_ARIMA_fit.png\",bbox_inches='tight')\n",
    "        self.plot_predict('ARIMA')\n",
    "    def arimax(self):\n",
    "        self.arimax = pf.ARIMAX(data=self.data,ar=7, ma=7,formula=self.formula(), family=pf.Normal())\n",
    "        self.arimax.plot_fit = types.MethodType(plot_fit, self.arimax)\n",
    "        self.arimax_res = self.arimax.fit(\"MLE\")\n",
    "        with stdoutIO() as s:\n",
    "            self.arimax_res.summary()\n",
    "        with open(PATH+self.target()+\"_ARIMAX.txt\", \"w\") as text_file:\n",
    "            text_file.write(s.getvalue())\n",
    "        self.arimax.plot_fit(figsize=(25,5),model='ARIMAX')\n",
    "        plt.savefig(PATH+self.target()+\"_ARIMAX_fit.png\",bbox_inches='tight')\n",
    "        self.plot_predict('ARIMAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_by_tail = edges().values_list('tail').annotate(weight=Sum('weight')).order_by('-weight')\n",
    "district_selected = list(group_by_tail[:9].values_list('tail',flat=True))+list(group_by_tail.filter(tail=170)[:1].values_list('tail',flat=True))\n",
    "\n",
    "q = None #Q(pickupDistrict=0)\n",
    "for t in district_selected:\n",
    "    for h in district_selected:\n",
    "        ets = EdgeTimeSeries(t,h)\n",
    "        if q is None:\n",
    "            q = Q(Q(pickupDistrict=t),Q(dropoffDistrict__in=ets.neighbour_tail))|  \\\n",
    "             Q(Q(dropoffDistrict=h),Q(pickupDistrict__in=ets.neighbour_head))|  \\\n",
    "             Q(Q(dropoffDistrict=t),Q(pickupDistrict=h))|  \\\n",
    "             Q(Q(dropoffDistrict=h),Q(pickupDistrict=t))\n",
    "        else:\n",
    "            q |= Q(Q(pickupDistrict=t),Q(dropoffDistrict__in=ets.neighbour_tail))|  \\\n",
    "                 Q(Q(dropoffDistrict=h),Q(pickupDistrict__in=ets.neighbour_head))|  \\\n",
    "                 Q(Q(dropoffDistrict=t),Q(pickupDistrict=h))|  \\\n",
    "                 Q(Q(dropoffDistrict=h),Q(pickupDistrict=t))\n",
    "\n",
    "neighbour_day = Trip.objects.all().filter(q).values('pickupDistrict','dropoffDistrict').order_by(). \\\n",
    "        annotate(weight=Count('pk'),total_amount=Avg('totalAmount'),day=Day('pickupTime'))\n",
    "neighbour_day_array = np.array(list(neighbour_day.values_list('day','pickupDistrict','dropoffDistrict','weight'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbour_day_tab = pd.pivot_table(pd.DataFrame(neighbour_day_array), values=3, index=0,\n",
    "                     columns=[1,2], aggfunc=np.sum).fillna(0)\n",
    "#neighbour_day_tab = pd.read_pickle('daily_table')\n",
    "neighbour_day_tab.columns = [neighbour_day_tab.columns.map('d{0[0]}_d{0[1]}'.format)]\n",
    "daily_table_full = pd.DataFrame(neighbour_day_tab.values)\n",
    "daily_table_full.index = neighbour_day_tab.index#pd.DatetimeIndex(.values.astype(datetime),dtype=datetime)\n",
    "daily_table_full.columns = neighbour_day_tab.columns.get_level_values(0)\n",
    "daily_table_full.to_pickle('daily_table_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_table_full = pd.read_pickle('daily_table_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphTimeSeries():\n",
    "    def __init__(self,daily_table_full,n_hotspots=10):\n",
    "        group_by_tail = edges().values_list('tail').annotate(weight=Sum('weight')).order_by('-weight')\n",
    "        district_selected = list(group_by_tail[:n_hotspots-1].values_list('tail',flat=True))+list(group_by_tail.filter(tail=170)[:1].values_list('tail',flat=True))\n",
    "        self.districts = district_selected\n",
    "        self.edges = []\n",
    "        for t in district_selected:\n",
    "            for h in district_selected:\n",
    "                self.edges.append(EdgeTimeSeries(t,h,daily_table_full))\n",
    "    def analyze(self):\n",
    "        for idx, ets in enumerate(self.edges):\n",
    "            if idx > 79:\n",
    "                print(idx)\n",
    "                ets.plot_serie()\n",
    "                ets.arima()\n",
    "                ets.arimax()\n",
    "                import gc\n",
    "                del ets\n",
    "                gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[190, 228, 219, 183, 100, 145, 259, 218, 151, 170]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_mobility = GraphTimeSeries(daily_table_full)\n",
    "taxi_mobility.analyze()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python34]",
   "language": "python",
   "name": "conda-env-python34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
